{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ BTC Price Prediction - Using Project Models\n",
                "\n",
                "Using `ModelFactory` with LSTM, GRU, Transformer, Ensemble from the codebase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Clone & Setup\n",
                "import os\n",
                "\n",
                "REPO = \"btc-price-prediction-hybrid-lstm-sentiment-crispdm\"\n",
                "if os.path.exists(REPO):\n",
                "    !rm -rf $REPO\n",
                "!git clone https://github.com/bimoBintang/$REPO.git\n",
                "os.chdir(REPO)\n",
                "\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q yfinance ta\n",
                "\n",
                "print(f\"\\n‚úÖ Working dir: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Data Collection & Feature Engineering\n",
                "import sys\n",
                "sys.path.insert(0, os.getcwd())\n",
                "\n",
                "import yfinance as yf\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import ta\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Get data\n",
                "print(\"Fetching BTC data...\")\n",
                "df = yf.Ticker('BTC-USD').history(period='max', interval='1d')\n",
                "df.columns = [c.lower() for c in df.columns]\n",
                "print(f\"Data: {len(df)} days\")\n",
                "\n",
                "# Technical Indicators\n",
                "df['sma_7'] = ta.trend.sma_indicator(df['close'], 7)\n",
                "df['sma_21'] = ta.trend.sma_indicator(df['close'], 21)\n",
                "df['sma_50'] = ta.trend.sma_indicator(df['close'], 50)\n",
                "df['ema_12'] = ta.trend.ema_indicator(df['close'], 12)\n",
                "df['ema_26'] = ta.trend.ema_indicator(df['close'], 26)\n",
                "df['rsi'] = ta.momentum.rsi(df['close'], 14)\n",
                "df['macd'] = ta.trend.macd(df['close'])\n",
                "df['macd_signal'] = ta.trend.macd_signal(df['close'])\n",
                "df['bb_high'] = ta.volatility.bollinger_hband(df['close'])\n",
                "df['bb_low'] = ta.volatility.bollinger_lband(df['close'])\n",
                "df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'])\n",
                "\n",
                "for lag in [1, 3, 7, 14]:\n",
                "    df[f'ret_{lag}d'] = df['close'].pct_change(lag)\n",
                "    df[f'close_lag{lag}'] = df['close'].shift(lag)\n",
                "\n",
                "df['target'] = df['close'].shift(-1)\n",
                "df = df.dropna()\n",
                "\n",
                "print(f\"Features: {len(df.columns)-1}, Samples: {len(df)}\")\n",
                "df['close'].plot(figsize=(14, 4), title='BTC Price')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Prepare Data\n",
                "import torch\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.preprocessing import RobustScaler\n",
                "\n",
                "feature_cols = [c for c in df.columns if c != 'target']\n",
                "X = df[feature_cols].values.astype(np.float32)\n",
                "y = df['target'].values.astype(np.float32)\n",
                "\n",
                "scaler_X = RobustScaler()\n",
                "scaler_y = RobustScaler()\n",
                "X_scaled = scaler_X.fit_transform(X)\n",
                "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
                "\n",
                "# Sequences\n",
                "SEQ_LEN = 30\n",
                "def create_sequences(X, y, seq_len):\n",
                "    Xs, ys = [], []\n",
                "    for i in range(len(X) - seq_len):\n",
                "        Xs.append(X[i:i+seq_len])\n",
                "        ys.append(y[i+seq_len])\n",
                "    return np.array(Xs), np.array(ys)\n",
                "\n",
                "X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LEN)\n",
                "\n",
                "# Split\n",
                "n = len(X_seq)\n",
                "train_end = int(n * 0.7)\n",
                "val_end = int(n * 0.85)\n",
                "\n",
                "X_train, y_train = X_seq[:train_end], y_seq[:train_end]\n",
                "X_val, y_val = X_seq[train_end:val_end], y_seq[train_end:val_end]\n",
                "X_test, y_test = X_seq[val_end:], y_seq[val_end:]\n",
                "\n",
                "train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)), batch_size=64, shuffle=True)\n",
                "val_loader = DataLoader(TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val)), batch_size=64)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. Create Models using ModelFactory\n",
                "from src.pipeline.models.model_factory import ModelFactory\n",
                "\n",
                "factory = ModelFactory(models_dir='trained_models')\n",
                "input_size = len(feature_cols)\n",
                "\n",
                "# Create all models\n",
                "models = factory.create_all_models(input_size=input_size, output_size=1)\n",
                "\n",
                "print(f\"\\nModels created: {list(models.keys())}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. Training Function\n",
                "import torch.nn as nn\n",
                "\n",
                "def train_model(model, name, epochs=100, patience=15):\n",
                "    model = model.to(device)\n",
                "    criterion = nn.HuberLoss()\n",
                "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
                "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
                "    \n",
                "    best_val = float('inf')\n",
                "    patience_counter = 0\n",
                "    train_hist, val_hist = [], []\n",
                "    \n",
                "    print(f\"\\nTraining {name}...\")\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        train_loss = 0\n",
                "        for X_b, y_b in train_loader:\n",
                "            X_b, y_b = X_b.to(device), y_b.to(device)\n",
                "            optimizer.zero_grad()\n",
                "            pred = model(X_b)\n",
                "            if pred.dim() > 1:\n",
                "                pred = pred.squeeze()\n",
                "            loss = criterion(pred, y_b)\n",
                "            loss.backward()\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "            optimizer.step()\n",
                "            train_loss += loss.item()\n",
                "        \n",
                "        model.eval()\n",
                "        val_loss = 0\n",
                "        with torch.no_grad():\n",
                "            for X_b, y_b in val_loader:\n",
                "                X_b, y_b = X_b.to(device), y_b.to(device)\n",
                "                pred = model(X_b)\n",
                "                if pred.dim() > 1:\n",
                "                    pred = pred.squeeze()\n",
                "                val_loss += criterion(pred, y_b).item()\n",
                "        \n",
                "        train_loss /= len(train_loader)\n",
                "        val_loss /= len(val_loader)\n",
                "        train_hist.append(train_loss)\n",
                "        val_hist.append(val_loss)\n",
                "        scheduler.step(val_loss)\n",
                "        \n",
                "        if val_loss < best_val:\n",
                "            best_val = val_loss\n",
                "            patience_counter = 0\n",
                "            best_state = model.state_dict().copy()\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "        \n",
                "        if (epoch+1) % 10 == 0:\n",
                "            print(f\"  Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
                "        \n",
                "        if patience_counter >= patience:\n",
                "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
                "            break\n",
                "    \n",
                "    model.load_state_dict(best_state)\n",
                "    print(f\"  Best val_loss: {best_val:.4f}\")\n",
                "    return model, train_hist, val_hist, best_val"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 6. Train All Models\n",
                "results = {}\n",
                "\n",
                "for name, model in models.items():\n",
                "    trained_model, train_h, val_h, best_v = train_model(model, name.upper())\n",
                "    results[name] = {\n",
                "        'model': trained_model,\n",
                "        'train_hist': train_h,\n",
                "        'val_hist': val_h,\n",
                "        'best_val': best_v\n",
                "    }\n",
                "    \n",
                "    # Save model\n",
                "    factory.save_model(trained_model, f\"{name}_best\", metadata={'val_loss': best_v})\n",
                "\n",
                "print(\"\\n‚úÖ All models trained!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 7. Training History\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "for ax, (name, data) in zip(axes.flatten(), results.items()):\n",
                "    ax.plot(data['train_hist'], label='Train')\n",
                "    ax.plot(data['val_hist'], label='Val')\n",
                "    ax.set_title(f\"{name.upper()} (Best Val: {data['best_val']:.4f})\")\n",
                "    ax.set_xlabel('Epoch')\n",
                "    ax.set_ylabel('Loss')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 8. Evaluation\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "\n",
                "X_test_t = torch.FloatTensor(X_test).to(device)\n",
                "y_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
                "\n",
                "metrics_list = []\n",
                "\n",
                "for name, data in results.items():\n",
                "    model = data['model']\n",
                "    model.eval()\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        pred_scaled = model(X_test_t).cpu().numpy()\n",
                "    \n",
                "    if pred_scaled.ndim > 1:\n",
                "        pred_scaled = pred_scaled.flatten()\n",
                "    \n",
                "    pred = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
                "    \n",
                "    mae = mean_absolute_error(y_actual, pred)\n",
                "    rmse = np.sqrt(mean_squared_error(y_actual, pred))\n",
                "    r2 = r2_score(y_actual, pred)\n",
                "    mape = np.mean(np.abs((y_actual - pred) / y_actual)) * 100\n",
                "    \n",
                "    metrics_list.append({'Model': name.upper(), 'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'R2': r2})\n",
                "    data['predictions'] = pred\n",
                "\n",
                "metrics_df = pd.DataFrame(metrics_list).set_index('Model')\n",
                "print(\"\\nüìä TEST SET METRICS\")\n",
                "print(\"=\"*60)\n",
                "print(metrics_df.to_string())\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Best model\n",
                "best_model = metrics_df['R2'].idxmax()\n",
                "print(f\"\\nüèÜ Best Model: {best_model} (R¬≤={metrics_df.loc[best_model, 'R2']:.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 9. Predictions Visualization\n",
                "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
                "\n",
                "for ax, (name, data) in zip(axes.flatten(), results.items()):\n",
                "    ax.plot(y_actual, label='Actual', alpha=0.7)\n",
                "    ax.plot(data['predictions'], label='Predicted', alpha=0.7)\n",
                "    r2 = metrics_df.loc[name.upper(), 'R2']\n",
                "    ax.set_title(f\"{name.upper()} (R¬≤={r2:.4f})\")\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 10. Model Comparison\n",
                "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
                "\n",
                "for ax, col in zip(axes, ['MAE', 'RMSE', 'MAPE', 'R2']):\n",
                "    values = metrics_df[col]\n",
                "    colors = ['green' if (col == 'R2' and v == values.max()) or (col != 'R2' and v == values.min()) else 'steelblue' for v in values]\n",
                "    ax.bar(values.index, values.values, color=colors)\n",
                "    ax.set_title(col)\n",
                "    ax.tick_params(axis='x', rotation=45)\n",
                "    for i, v in enumerate(values):\n",
                "        fmt = f'{v:.4f}' if col == 'R2' else f'{v:.2f}' if col == 'MAPE' else f'${v:,.0f}'\n",
                "        ax.text(i, v, fmt, ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüìÅ Saved models:\")\n",
                "print(factory.list_saved_models())"
            ]
        }
    ]
}